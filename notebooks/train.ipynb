{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "__lMuDfIYKlu"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from math import ceil\n",
    "import seaborn as sns\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from math import sqrt\n",
    "import holidays\n",
    "import catboost as ctb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WINJFdJHYKl3"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/sales_transformed_with_coords_metro.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = df.apply(lambda x: datetime(int(x['year']), int(x['month']), 1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find empty uninformative brand with no sales for whole period\n",
    "df_brand_sum = df.groupby(['brand'])['sales'].sum().reset_index()\n",
    "useless_brands = df_brand_sum[df_brand_sum['sales'] <= 0]['brand'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df[df['brand'] == useless_brands[0]].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop Nan rows\n",
    "df = df.dropna(subset=['sales', 'district'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lag features for store sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "colab_type": "code",
    "id": "yAn03Bo6YKnI",
    "outputId": "8ace8160-33cf-4d97-d33f-3282627c3dfc"
   },
   "outputs": [],
   "source": [
    "month_revenues = df.groupby(['address', 'date']).agg({'sales': ['sum', 'mean', 'std']}).reset_index()\n",
    "month_revenues.columns = ['address', 'date', 'sales_sum', 'sales_mean', 'sales_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_revenues['lag_1_store_sales_sum'] =  month_revenues.groupby('address')['sales_sum'].shift(1)\n",
    "month_revenues['lag_1_store_sales_mean'] =  month_revenues.groupby('address')['sales_mean'].shift(1)\n",
    "month_revenues['lag_1_store_sales_std'] =  month_revenues.groupby('address')['sales_std'].shift(1)\n",
    "\n",
    "month_revenues['lag_2_store_sales_sum'] =  month_revenues.groupby('address')['sales_sum'].shift(2)\n",
    "month_revenues['lag_2_store_sales_mean'] =  month_revenues.groupby('address')['sales_mean'].shift(2)\n",
    "month_revenues['lag_2_store_sales_std'] =  month_revenues.groupby('address')['sales_std'].shift(2)\n",
    "\n",
    "month_revenues['lag_3_store_sales_sum'] =  month_revenues.groupby('address')['sales_sum'].shift(3)\n",
    "month_revenues['lag_3_store_sales_mean'] =  month_revenues.groupby('address')['sales_mean'].shift(3)\n",
    "month_revenues['lag_3_store_sales_std'] =  month_revenues.groupby('address')['sales_std'].shift(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eMy6c_yYYKnY"
   },
   "outputs": [],
   "source": [
    "left_df =  df.set_index(['address', 'date'])\n",
    "right_df = month_revenues.set_index(['address', 'date'])\n",
    "merged_df = pd.merge(left_df, right_df, left_index=True, right_index=True, how='left', sort=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[merged_df['address'] == 'Россия, г Москва, ш Ярославское, д 63'].tail(27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lag features for brand sales in each store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cpCizvXGYKna"
   },
   "outputs": [],
   "source": [
    "df_grouped_by_brand = df.groupby(['address', 'brand', 'date']).agg({'sales':'sum'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_by_brand['lag_1_brand_sales'] = df_grouped_by_brand.groupby(['address', 'brand'])['sales'].shift(1)\n",
    "df_grouped_by_brand['lag_2_brand_sales'] = df_grouped_by_brand.groupby(['address', 'brand'])['sales'].shift(2)\n",
    "df_grouped_by_brand['lag_3_brand_sales'] = df_grouped_by_brand.groupby(['address', 'brand'])['sales'].shift(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_by_brand[df_grouped_by_brand['brand'] == 'Царская Чарка'].tail(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_df =  merged_df.set_index(['address', 'brand', 'date'])\n",
    "right_df = df_grouped_by_brand.drop('sales', axis=1).set_index(['address', 'brand', 'date'])\n",
    "df = pd.merge(left_df, right_df, left_index=True, right_index=True, how='left', sort=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['address'] == 'Россия, г Москва, ш Ярославское, д 69') & (df['brand'] == 'Царская Чарка')].tail(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Days, Holidays count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f8Uqk7pzYKnB"
   },
   "outputs": [],
   "source": [
    "days = pd.Series([0, 31,28,31,30,31,30,31,31,30,31,30,31])\n",
    "df['days'] = df['month'].map(days).astype(np.int64)\n",
    "df['days'] = df['days'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TtsgsxAoYKnz"
   },
   "outputs": [],
   "source": [
    "ru_holidays = holidays.Russia()\n",
    "\n",
    "def get_holidays_count(month_start):\n",
    "    month_start = pd.to_datetime(month_start)\n",
    "    month_end = month_start + relativedelta(months=1)\n",
    "    return len(ru_holidays[month_start:month_end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KPCjgBhuYKn2"
   },
   "outputs": [],
   "source": [
    "df['holidays_cnt'] = df['date'].apply(get_holidays_count).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1dQJJre8YKn7"
   },
   "outputs": [],
   "source": [
    "df = df.drop(['location', 'Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VApP76JQYKoF"
   },
   "source": [
    "## Train/Validation/Test split\n",
    "\n",
    "I will use last month for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ix-oaxAYKoF"
   },
   "outputs": [],
   "source": [
    "train_set = df[df['date'] < '2019-12-01'].reset_index()\n",
    "test_set = df[df['date'] >= '2019-12-01'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JRPKMxXfYKoI"
   },
   "outputs": [],
   "source": [
    "# sanity check\n",
    "len(test_set) + len(train_set) == len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xgm23EZqYKoQ"
   },
   "outputs": [],
   "source": [
    "def train_val_split(df, start_date):\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    in_three_months = (start_date + relativedelta(months=3)).replace(day=1)\n",
    "    in_four_months = (start_date + relativedelta(months=4)).replace(day=1)\n",
    "    return train_set.loc[\n",
    "        (train_set['date'] >= start_date) & (train_set['date'] < in_three_months)\n",
    "    ].index,\\\n",
    "    train_set.loc[\n",
    "        (train_set['date'] >= in_three_months) & (train_set['date'] < in_four_months)\n",
    "    ].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fpGa4lsdYKoe"
   },
   "outputs": [],
   "source": [
    "def get_cv_iterator(dataset):\n",
    "    for year in (2018, 2019):\n",
    "        for month in range(1, 13):\n",
    "            d = '{}-{}-01'.format(year, month)\n",
    "            if d == '2019-9-01':\n",
    "                break\n",
    "            yield train_val_split(dataset, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_iterator = get_cv_iterator(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pa6RymF0YKop"
   },
   "outputs": [],
   "source": [
    "X = train_set.drop(['sales', 'date', 'address'], axis=1)\n",
    "y = train_set['sales']\n",
    "\n",
    "X_test = test_set.drop(['sales', 'date', 'address'], axis=1)\n",
    "y_test = test_set['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vbx8fPGnYKor"
   },
   "outputs": [],
   "source": [
    "# sanity check\n",
    "len(X_test) + len(X) == len(df), len(y) + len(y_test) == len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pbgeM70mYKox"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a-RZUjmhYKoz"
   },
   "source": [
    "## Baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "imDZOlK0YKo1"
   },
   "outputs": [],
   "source": [
    "def get_rmse(y_actual, y_predicted):\n",
    "    return sqrt(mean_squared_error(y_actual, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse_per_brand(y_actual, y_predicted):\n",
    "    idx = y_actual.index\n",
    "    stats = []\n",
    "    brands = X_test.loc[X_test.index.isin(idx)]['brand'].unique().tolist()\n",
    "    y_pred_df = pd.DataFrame({'y_pred': y_predicted})\n",
    "    y_actual_pred_df = pd.concat([y_actual, y_pred_df], axis=1)\n",
    "    for brand in brands:\n",
    "        brand_idx = X_test.loc[(X_test.index.isin(idx)) & (X_test['brand'] == brand)].index\n",
    "        smse = sqrt(mean_squared_error(y_actual.loc[brand_idx], y_pred_df.loc[brand_idx]))\n",
    "        stats.append((brand, smse))\n",
    "    return list(sorted(stats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g3-7hUerYKo3"
   },
   "source": [
    "1. Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7tlJFxZmYKo4"
   },
   "outputs": [],
   "source": [
    "CONS = 1\n",
    "rmses = []\n",
    "for _, val_idx in cv_iterator:\n",
    "    y_actual = y.loc[val_idx]\n",
    "    y_predicted = [CONS] * len(y_actual)\n",
    "    rmses.append(get_rmse(y_actual, y_predicted))\n",
    "np.mean(rmses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZQiv5zxQYKo7"
   },
   "source": [
    "2. Prediction by last period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o_iqv10HYKo8"
   },
   "outputs": [],
   "source": [
    "def get_prev_sales(row):\n",
    "        prev_date = pd.to_datetime(row['date']) - relativedelta(months=1)\n",
    "        prev_date = prev_date.replace(day=1)\n",
    "        last_y = train_set[\n",
    "            (train_set['month'] == prev_date) & \n",
    "            (train_set['brand'] == row['brand'])\n",
    "        ]['sales']\n",
    "        if last_y.any():\n",
    "            last_y = last_y.iloc[0]['sales']\n",
    "        else:\n",
    "            last_y = 0\n",
    "        return last_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5YxlHhvyYKo-"
   },
   "outputs": [],
   "source": [
    "rmses = []\n",
    "for _, val_idx in cv_iterator:\n",
    "    y_actual = y.loc[val_idx]\n",
    "    y_predicted = train_set.loc[val_idx].apply(get_prev_sales, axis=1)\n",
    "    rmses.append(get_rmse(y_actual, y_predicted))\n",
    "np.mean(rmses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fYlveQ9eYKpC"
   },
   "source": [
    "3. Mean for last 5 periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ucv-0legYKpD"
   },
   "outputs": [],
   "source": [
    "def get_prev_5_sales(row):\n",
    "        y_previous = []\n",
    "        for i in range(1, 6):\n",
    "            prev_date = pd.to_datetime(row['date']) - relativedelta(months=i)\n",
    "            prev_date = prev_date.replace(day=1)\n",
    "            prev_y = train_set[\n",
    "                (train_set['month'] == prev_date) & \n",
    "                (train_set['brand'] == row['brand'])\n",
    "            ]['sales']\n",
    "            if prev_y.any():\n",
    "                prev_y = prev_y.iloc[0]['sales']\n",
    "            else:\n",
    "                prev_y = 0\n",
    "            y_previous.append(prev_y)\n",
    "        return np.mean(y_previous or [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SnRCbmcAYKpF"
   },
   "outputs": [],
   "source": [
    "rmses = []\n",
    "for _, val_idx in cv_iterator:\n",
    "    y_actual = y.loc[val_idx]\n",
    "    y_predicted = train_set.loc[val_idx].apply(get_prev_5_sales, axis=1)\n",
    "    rmses.append(get_rmse(y_actual, y_predicted))\n",
    "np.mean(rmses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h04X-PZyYKpI"
   },
   "source": [
    "4. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L4nKAQuNYKpJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "rmses = []\n",
    "for train_idx, val_idx in cv_iterator:\n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(X.loc[train_idx], y.loc[train_idx])\n",
    "    y_val_predicted = lin_reg.predict(train_set.loc[val_idx])\n",
    "    rmse = get_rmse(y.loc[val_idx], y_val_predicted)\n",
    "    rmses.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hieWtbmqYKpR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GFwAM9n_YKpT"
   },
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X.columns)\n",
    "categorical_features_indices = np.where((X.dtypes != np.float) & (X.dtypes != np.int))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7a7OSe3_YKpU"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"loss_function\": \"RMSE\",\n",
    "    \"eval_metric\": \"RMSE\",\n",
    "    \"iterations\": 1200,\n",
    "    \"random_seed\": 42,\n",
    "    \"od_wait\": 50,\n",
    "    \"od_type\": \"Iter\",\n",
    "    \"thread_count\": 10\n",
    "}\n",
    "\n",
    "grid = {\n",
    "    'learning_rate': [0.03, 0.06, 0.08],\n",
    "    'depth': [10, 12, 15],\n",
    "}\n",
    "\n",
    "ctb_data = ctb.Pool(X, y, cat_features=categorical_features_indices)\n",
    "\n",
    "model = ctb.CatBoostRegressor(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HMuFAFmTYKpY"
   },
   "outputs": [],
   "source": [
    "grid_search_result = model.grid_search(grid, ctb_data, plot=True, cv=cv_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params = grid_search_result['params']\n",
    "best_params = dict(learning_rate=0.06, depth=12)\n",
    "params.update(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = ctb.cv(ctb_data, params, plot=\"True\", folds=cv_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TdgjFRGLYKpa"
   },
   "outputs": [],
   "source": [
    "model = ctb.CatBoostRegressor(**params)\n",
    "model.fit(ctb_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "get_rmse(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot RMSE per each brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_brand_stats = sorted(get_rmse_per_brand(y_test, y_pred), key=lambda x: -x[1])\n",
    "per_brand_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40,8))\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.bar([x[0] for x in per_brand_stats[90:]], [x[1] for x in per_brand_stats[90:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = sorted(zip(X.columns, model.get_feature_importance(verbose=True)), key=lambda k: -k[1])\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40,8))\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.bar([x[0] for x in feature_importances], [x[1] for x in feature_importances])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('catboost_model_with_pool', pool=ctb_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Light GMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['brand', 'store_format', 'district']:\n",
    "    X[col] = X[col].astype('category')\n",
    "    X_test[col] = X_test[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rounds = 100000\n",
    "\n",
    "parameters = {\n",
    "    #default\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"num_threads\": 10,\n",
    "    \"metric\": \"rmse\",\n",
    "    \"seed\": 42,\n",
    "    \n",
    "    #regularization\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"subsample\": 0.8,\n",
    "    \"subsample_freq\": 1,\n",
    "    \"min_data_in_leaf\": 15,\n",
    "    \n",
    "    #categorical features\n",
    "    'cat_smooth': 10,\n",
    "    'min_data_per_group': 50,\n",
    "}\n",
    "lgb_train = lgb.Dataset(X, label=y, free_raw_data=False, categorical_feature=['brand', 'store_format', 'district'])\n",
    "result = lgb.cv(\n",
    "    parameters, \n",
    "    lgb_train, \n",
    "    n_rounds, \n",
    "    folds=cv_iterator, \n",
    "    early_stopping_rounds=50, \n",
    "    verbose_eval=100, \n",
    "    eval_train_metric=True, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_district = pd.get_dummies(df['district'])\n",
    "dummy_brand = pd.get_dummies(df['brand'])\n",
    "dummy_store_format = pd.get_dummies(df['store_format'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, dummy_district, dummy_brand, dummy_store_format], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ix-oaxAYKoF"
   },
   "outputs": [],
   "source": [
    "train_set = df[df['date'] < '2019-12-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fpGa4lsdYKoe"
   },
   "outputs": [],
   "source": [
    "cv_iterator = list(get_cv_iterator(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pa6RymF0YKop"
   },
   "outputs": [],
   "source": [
    "X = train_set.drop(['sales', 'date', 'address', 'district', 'store_format', 'brand'], axis=1)\n",
    "y = train_set['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear RAM\n",
    "del month_revenues, left_df, right_df, merged_df, df_grouped_by_brand\n",
    "del dummy_district, dummy_brand, dummy_store_format\n",
    "del df, train_set\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    #default\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"eta\": 0.01,\n",
    "    \"verbosity\": 0,\n",
    "    \"nthread\": 10,\n",
    "    \"random_seed\": 1,\n",
    "    \"eval_metric\": \"rmse\",\n",
    "    \"max_depth\": 10,\n",
    "    \n",
    "    \"subsample\": 1,\n",
    "    \"colsample_bytree\": 1,\n",
    "    \n",
    "    \"tree_method\": \"hist\",\n",
    "    \"grow_policy\": \"lossguide\"\n",
    "}\n",
    "\n",
    "\n",
    "model = xgb.XGBRegressor(**parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_rmses = []\n",
    "for train_idx, val_idx in cv_iterator:\n",
    "    model = xgb.XGBRegressor(**parameters)\n",
    "    model.fit(X.loc[train_idx], y[train_idx], eval_metric='rmse')\n",
    "    y_pred = model.predict(X.loc[val_idx])\n",
    "    rmse = get_rmse(y[val_idx], y_pred)\n",
    "    print('val RMSE: {}'.format(rmse))\n",
    "    cv_rmses.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.mean(cv_rmses), np.std(cv_rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "EDA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
